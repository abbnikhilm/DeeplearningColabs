{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of 2b. Boston Housing Prices_Eager_Normalization.ipynb","version":"0.3.2","provenance":[{"file_id":"12JeA8QijZcWK0A9XFIP8SIiJuhh8l08b","timestamp":1561376446842}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"X_cdgs6Gtnsc","colab_type":"text"},"source":["#### Load TensorFlow and Enable Eager Execution"]},{"cell_type":"code","metadata":{"id":"5b_EywEw4MMe","colab_type":"code","colab":{}},"source":["import tensorflow as tf"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mbkpLj1A4qbS","colab_type":"code","outputId":"67cc93d8-487c-44f6-f982-ae1538a1915f","executionInfo":{"status":"ok","timestamp":1561376487182,"user_tz":-330,"elapsed":1484,"user":{"displayName":"Nikhil Madhusudhan","photoUrl":"https://lh4.googleusercontent.com/-YnXjatesaTE/AAAAAAAAAAI/AAAAAAAAACU/kzbw4Qh1c_g/s64/photo.jpg","userId":"15028125124945084753"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["tf.__version__"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'1.14.0-rc1'"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"hvZtaumXAyQ6","colab_type":"code","colab":{}},"source":["tf.enable_eager_execution()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6ZqHpTR3zk6G","colab_type":"code","colab":{}},"source":["from sklearn.preprocessing import Normalizer"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"21W7saMGt1_F","colab_type":"text"},"source":["#### Load Data"]},{"cell_type":"code","metadata":{"id":"2F_QcYwH4u7I","colab_type":"code","colab":{}},"source":["(train_x, train_y),(_,_) = tf.keras.datasets.boston_housing.load_data(test_split=0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pcDQYh3SBUNV","colab_type":"code","outputId":"2aaa2896-697c-4862-bd32-b6d0564e828b","executionInfo":{"status":"ok","timestamp":1561376489748,"user_tz":-330,"elapsed":926,"user":{"displayName":"Nikhil Madhusudhan","photoUrl":"https://lh4.googleusercontent.com/-YnXjatesaTE/AAAAAAAAAAI/AAAAAAAAACU/kzbw4Qh1c_g/s64/photo.jpg","userId":"15028125124945084753"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["train_x.dtype"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dtype('float64')"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"lADXNbMKGH_g","colab":{}},"source":["train_x = train_x.astype('float32')\n","train_y = train_y.astype('float32')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TKDsS4vKGl3E","colab_type":"code","outputId":"8f6242a1-75a3-4e20-aef7-70f0aaad7580","executionInfo":{"status":"ok","timestamp":1561376492303,"user_tz":-330,"elapsed":752,"user":{"displayName":"Nikhil Madhusudhan","photoUrl":"https://lh4.googleusercontent.com/-YnXjatesaTE/AAAAAAAAAAI/AAAAAAAAACU/kzbw4Qh1c_g/s64/photo.jpg","userId":"15028125124945084753"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["train_x.shape"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(506, 13)"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"FXk9VbBz_Mbh","colab_type":"code","outputId":"2a379740-956d-4a5f-a744-6f9797d06ad7","executionInfo":{"status":"ok","timestamp":1561376494061,"user_tz":-330,"elapsed":1146,"user":{"displayName":"Nikhil Madhusudhan","photoUrl":"https://lh4.googleusercontent.com/-YnXjatesaTE/AAAAAAAAAAI/AAAAAAAAACU/kzbw4Qh1c_g/s64/photo.jpg","userId":"15028125124945084753"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["train_y.shape"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(506,)"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"NPqcYGULzifH","colab_type":"code","colab":{}},"source":["transformer = Normalizer()\n","train_x = transformer.fit_transform(train_x)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"j7kzp_cATnbn","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fOIoE3qCt9Wp","colab_type":"text"},"source":["#### Build Model"]},{"cell_type":"markdown","metadata":{"id":"uSMg5HDluCZG","colab_type":"text"},"source":["Define Weights and Bias"]},{"cell_type":"code","metadata":{"id":"1qHkc0mS_KZP","colab_type":"code","colab":{}},"source":["#We are initializing weights and Bias with Zero\n","w = tf.zeros(shape=(13,1))\n","b = tf.zeros(shape=(1))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"njFtCLMGD4et","colab_type":"code","colab":{}},"source":["xw_matmul = tf.matmul(train_x, w)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MP8U92hduNeV","colab_type":"text"},"source":["Define a function to calculate prediction"]},{"cell_type":"code","metadata":{"id":"ARk9SVAb_jBA","colab_type":"code","colab":{}},"source":["def prediction(x, w, b):\n","    \n","    xw_matmul = tf.matmul(x, w)\n","    y = tf.add(xw_matmul, b)\n","    \n","    return y"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0QKcoDtbuhDl","colab_type":"text"},"source":["Function to calculate Loss (Mean Squared Error)"]},{"cell_type":"code","metadata":{"id":"zEkRNWEa_q45","colab_type":"code","colab":{}},"source":["def loss(y_actual, y_predicted):\n","    \n","    diff = y_actual - y_predicted\n","    sqr = tf.square(diff)\n","    avg = tf.reduce_mean(sqr)\n","    \n","    return avg"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2U2j7okPul9V","colab_type":"text"},"source":["Function to train the Model\n","\n","1.   Record all the mathematical steps to calculate Loss\n","2.   Calculate Gradients of Loss w.r.t weights and bias\n","3.   Update Weights and Bias based on gradients and learning rate\n","\n"]},{"cell_type":"code","metadata":{"id":"r_Zu3u8IARZu","colab_type":"code","colab":{}},"source":["def train(x, y_actual, w, b, learning_rate=0.01):\n","    \n","    #Record mathematical operations on 'tape' to calculate loss\n","    with tf.GradientTape() as t:\n","        \n","        t.watch([w,b])\n","        \n","        current_prediction = prediction(x, w, b)\n","        current_loss = loss(y_actual, current_prediction)\n","    \n","    #Calculate Gradients for Loss with respect to Weights and Bias\n","    dw, db = t.gradient(current_loss,[w, b])\n","    \n","    #Update Weights and Bias\n","    w = w - learning_rate*dw\n","    b = b - learning_rate*db\n","    \n","    return w, b"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zcXDZ6N5vNw-","colab_type":"text"},"source":["#### Start Training"]},{"cell_type":"code","metadata":{"id":"gOY134RfEpbq","colab_type":"code","outputId":"77cd009b-4000-4f68-8243-77c7255310a1","executionInfo":{"status":"ok","timestamp":1561376533136,"user_tz":-330,"elapsed":5309,"user":{"displayName":"Nikhil Madhusudhan","photoUrl":"https://lh4.googleusercontent.com/-YnXjatesaTE/AAAAAAAAAAI/AAAAAAAAACU/kzbw4Qh1c_g/s64/photo.jpg","userId":"15028125124945084753"}},"colab":{"base_uri":"https://localhost:8080/","height":16817}},"source":["for i in range(1000):\n","    \n","    w, b = train(train_x, train_y, w, b)\n","    print('Current Loss on iteration', i, loss(train_y, prediction(train_x, w, b)).numpy())\n","    "],"execution_count":17,"outputs":[{"output_type":"stream","text":["Current Loss on iteration 0 298.2792\n","Current Loss on iteration 1 282.1232\n","Current Loss on iteration 2 267.1898\n","Current Loss on iteration 3 253.38652\n","Current Loss on iteration 4 240.62787\n","Current Loss on iteration 5 228.83473\n","Current Loss on iteration 6 217.93405\n","Current Loss on iteration 7 207.85832\n","Current Loss on iteration 8 198.54506\n","Current Loss on iteration 9 189.9366\n","Current Loss on iteration 10 181.9796\n","Current Loss on iteration 11 174.62473\n","Current Loss on iteration 12 167.82646\n","Current Loss on iteration 13 161.54263\n","Current Loss on iteration 14 155.73434\n","Current Loss on iteration 15 150.36557\n","Current Loss on iteration 16 145.4031\n","Current Loss on iteration 17 140.81613\n","Current Loss on iteration 18 136.57628\n","Current Loss on iteration 19 132.65729\n","Current Loss on iteration 20 129.03482\n","Current Loss on iteration 21 125.68647\n","Current Loss on iteration 22 122.5915\n","Current Loss on iteration 23 119.73073\n","Current Loss on iteration 24 117.086426\n","Current Loss on iteration 25 114.64222\n","Current Loss on iteration 26 112.38295\n","Current Loss on iteration 27 110.29462\n","Current Loss on iteration 28 108.36432\n","Current Loss on iteration 29 106.58006\n","Current Loss on iteration 30 104.93081\n","Current Loss on iteration 31 103.406334\n","Current Loss on iteration 32 101.99722\n","Current Loss on iteration 33 100.6947\n","Current Loss on iteration 34 99.49073\n","Current Loss on iteration 35 98.37785\n","Current Loss on iteration 36 97.34915\n","Current Loss on iteration 37 96.39827\n","Current Loss on iteration 38 95.51934\n","Current Loss on iteration 39 94.706894\n","Current Loss on iteration 40 93.955894\n","Current Loss on iteration 41 93.26171\n","Current Loss on iteration 42 92.620026\n","Current Loss on iteration 43 92.02687\n","Current Loss on iteration 44 91.478584\n","Current Loss on iteration 45 90.971756\n","Current Loss on iteration 46 90.50326\n","Current Loss on iteration 47 90.07018\n","Current Loss on iteration 48 89.66986\n","Current Loss on iteration 49 89.299805\n","Current Loss on iteration 50 88.957726\n","Current Loss on iteration 51 88.6415\n","Current Loss on iteration 52 88.34918\n","Current Loss on iteration 53 88.07896\n","Current Loss on iteration 54 87.82915\n","Current Loss on iteration 55 87.59823\n","Current Loss on iteration 56 87.38474\n","Current Loss on iteration 57 87.18739\n","Current Loss on iteration 58 87.00495\n","Current Loss on iteration 59 86.83628\n","Current Loss on iteration 60 86.68036\n","Current Loss on iteration 61 86.5362\n","Current Loss on iteration 62 86.40292\n","Current Loss on iteration 63 86.27971\n","Current Loss on iteration 64 86.16578\n","Current Loss on iteration 65 86.06046\n","Current Loss on iteration 66 85.96307\n","Current Loss on iteration 67 85.87304\n","Current Loss on iteration 68 85.78978\n","Current Loss on iteration 69 85.71281\n","Current Loss on iteration 70 85.64161\n","Current Loss on iteration 71 85.57579\n","Current Loss on iteration 72 85.51493\n","Current Loss on iteration 73 85.45864\n","Current Loss on iteration 74 85.406586\n","Current Loss on iteration 75 85.35844\n","Current Loss on iteration 76 85.31391\n","Current Loss on iteration 77 85.27273\n","Current Loss on iteration 78 85.23464\n","Current Loss on iteration 79 85.199394\n","Current Loss on iteration 80 85.16679\n","Current Loss on iteration 81 85.136635\n","Current Loss on iteration 82 85.108734\n","Current Loss on iteration 83 85.08292\n","Current Loss on iteration 84 85.05902\n","Current Loss on iteration 85 85.03692\n","Current Loss on iteration 86 85.01645\n","Current Loss on iteration 87 84.99751\n","Current Loss on iteration 88 84.97998\n","Current Loss on iteration 89 84.963745\n","Current Loss on iteration 90 84.94872\n","Current Loss on iteration 91 84.93481\n","Current Loss on iteration 92 84.92191\n","Current Loss on iteration 93 84.909966\n","Current Loss on iteration 94 84.8989\n","Current Loss on iteration 95 84.88865\n","Current Loss on iteration 96 84.87916\n","Current Loss on iteration 97 84.870346\n","Current Loss on iteration 98 84.862175\n","Current Loss on iteration 99 84.85461\n","Current Loss on iteration 100 84.84757\n","Current Loss on iteration 101 84.84106\n","Current Loss on iteration 102 84.83501\n","Current Loss on iteration 103 84.829384\n","Current Loss on iteration 104 84.824165\n","Current Loss on iteration 105 84.81932\n","Current Loss on iteration 106 84.814804\n","Current Loss on iteration 107 84.81062\n","Current Loss on iteration 108 84.80672\n","Current Loss on iteration 109 84.80309\n","Current Loss on iteration 110 84.79971\n","Current Loss on iteration 111 84.79656\n","Current Loss on iteration 112 84.793625\n","Current Loss on iteration 113 84.790886\n","Current Loss on iteration 114 84.78834\n","Current Loss on iteration 115 84.78594\n","Current Loss on iteration 116 84.783714\n","Current Loss on iteration 117 84.78164\n","Current Loss on iteration 118 84.779686\n","Current Loss on iteration 119 84.77786\n","Current Loss on iteration 120 84.77614\n","Current Loss on iteration 121 84.77453\n","Current Loss on iteration 122 84.77302\n","Current Loss on iteration 123 84.77159\n","Current Loss on iteration 124 84.77026\n","Current Loss on iteration 125 84.769005\n","Current Loss on iteration 126 84.767815\n","Current Loss on iteration 127 84.766685\n","Current Loss on iteration 128 84.76564\n","Current Loss on iteration 129 84.76463\n","Current Loss on iteration 130 84.76367\n","Current Loss on iteration 131 84.762764\n","Current Loss on iteration 132 84.76192\n","Current Loss on iteration 133 84.76109\n","Current Loss on iteration 134 84.760315\n","Current Loss on iteration 135 84.75958\n","Current Loss on iteration 136 84.758865\n","Current Loss on iteration 137 84.758194\n","Current Loss on iteration 138 84.75754\n","Current Loss on iteration 139 84.75691\n","Current Loss on iteration 140 84.75632\n","Current Loss on iteration 141 84.75574\n","Current Loss on iteration 142 84.75517\n","Current Loss on iteration 143 84.75464\n","Current Loss on iteration 144 84.75412\n","Current Loss on iteration 145 84.753624\n","Current Loss on iteration 146 84.75313\n","Current Loss on iteration 147 84.75266\n","Current Loss on iteration 148 84.7522\n","Current Loss on iteration 149 84.75175\n","Current Loss on iteration 150 84.75132\n","Current Loss on iteration 151 84.75089\n","Current Loss on iteration 152 84.75047\n","Current Loss on iteration 153 84.75006\n","Current Loss on iteration 154 84.749664\n","Current Loss on iteration 155 84.749275\n","Current Loss on iteration 156 84.74889\n","Current Loss on iteration 157 84.74852\n","Current Loss on iteration 158 84.74815\n","Current Loss on iteration 159 84.74779\n","Current Loss on iteration 160 84.74744\n","Current Loss on iteration 161 84.74708\n","Current Loss on iteration 162 84.74674\n","Current Loss on iteration 163 84.74638\n","Current Loss on iteration 164 84.74605\n","Current Loss on iteration 165 84.74571\n","Current Loss on iteration 166 84.74538\n","Current Loss on iteration 167 84.74505\n","Current Loss on iteration 168 84.74473\n","Current Loss on iteration 169 84.74441\n","Current Loss on iteration 170 84.744095\n","Current Loss on iteration 171 84.743774\n","Current Loss on iteration 172 84.74347\n","Current Loss on iteration 173 84.743164\n","Current Loss on iteration 174 84.74285\n","Current Loss on iteration 175 84.742546\n","Current Loss on iteration 176 84.74224\n","Current Loss on iteration 177 84.741936\n","Current Loss on iteration 178 84.741646\n","Current Loss on iteration 179 84.74135\n","Current Loss on iteration 180 84.74105\n","Current Loss on iteration 181 84.740746\n","Current Loss on iteration 182 84.740456\n","Current Loss on iteration 183 84.740166\n","Current Loss on iteration 184 84.73988\n","Current Loss on iteration 185 84.7396\n","Current Loss on iteration 186 84.7393\n","Current Loss on iteration 187 84.73902\n","Current Loss on iteration 188 84.73874\n","Current Loss on iteration 189 84.73846\n","Current Loss on iteration 190 84.738174\n","Current Loss on iteration 191 84.7379\n","Current Loss on iteration 192 84.73762\n","Current Loss on iteration 193 84.737335\n","Current Loss on iteration 194 84.73705\n","Current Loss on iteration 195 84.73678\n","Current Loss on iteration 196 84.7365\n","Current Loss on iteration 197 84.73622\n","Current Loss on iteration 198 84.73596\n","Current Loss on iteration 199 84.73568\n","Current Loss on iteration 200 84.73541\n","Current Loss on iteration 201 84.73514\n","Current Loss on iteration 202 84.73486\n","Current Loss on iteration 203 84.7346\n","Current Loss on iteration 204 84.73433\n","Current Loss on iteration 205 84.734055\n","Current Loss on iteration 206 84.73379\n","Current Loss on iteration 207 84.73353\n","Current Loss on iteration 208 84.73326\n","Current Loss on iteration 209 84.733\n","Current Loss on iteration 210 84.732735\n","Current Loss on iteration 211 84.732475\n","Current Loss on iteration 212 84.73221\n","Current Loss on iteration 213 84.73194\n","Current Loss on iteration 214 84.7317\n","Current Loss on iteration 215 84.73143\n","Current Loss on iteration 216 84.73116\n","Current Loss on iteration 217 84.7309\n","Current Loss on iteration 218 84.730644\n","Current Loss on iteration 219 84.7304\n","Current Loss on iteration 220 84.73013\n","Current Loss on iteration 221 84.72988\n","Current Loss on iteration 222 84.72963\n","Current Loss on iteration 223 84.72936\n","Current Loss on iteration 224 84.72912\n","Current Loss on iteration 225 84.72887\n","Current Loss on iteration 226 84.72861\n","Current Loss on iteration 227 84.728355\n","Current Loss on iteration 228 84.72812\n","Current Loss on iteration 229 84.72785\n","Current Loss on iteration 230 84.7276\n","Current Loss on iteration 231 84.727356\n","Current Loss on iteration 232 84.72711\n","Current Loss on iteration 233 84.72686\n","Current Loss on iteration 234 84.726616\n","Current Loss on iteration 235 84.726364\n","Current Loss on iteration 236 84.72612\n","Current Loss on iteration 237 84.725876\n","Current Loss on iteration 238 84.72563\n","Current Loss on iteration 239 84.72538\n","Current Loss on iteration 240 84.72515\n","Current Loss on iteration 241 84.7249\n","Current Loss on iteration 242 84.724655\n","Current Loss on iteration 243 84.72441\n","Current Loss on iteration 244 84.72418\n","Current Loss on iteration 245 84.72393\n","Current Loss on iteration 246 84.723694\n","Current Loss on iteration 247 84.72344\n","Current Loss on iteration 248 84.72322\n","Current Loss on iteration 249 84.72298\n","Current Loss on iteration 250 84.72274\n","Current Loss on iteration 251 84.7225\n","Current Loss on iteration 252 84.72226\n","Current Loss on iteration 253 84.72203\n","Current Loss on iteration 254 84.72179\n","Current Loss on iteration 255 84.72156\n","Current Loss on iteration 256 84.72133\n","Current Loss on iteration 257 84.721085\n","Current Loss on iteration 258 84.72086\n","Current Loss on iteration 259 84.72063\n","Current Loss on iteration 260 84.72039\n","Current Loss on iteration 261 84.72016\n","Current Loss on iteration 262 84.71994\n","Current Loss on iteration 263 84.719696\n","Current Loss on iteration 264 84.719475\n","Current Loss on iteration 265 84.719246\n","Current Loss on iteration 266 84.71902\n","Current Loss on iteration 267 84.71879\n","Current Loss on iteration 268 84.71856\n","Current Loss on iteration 269 84.71834\n","Current Loss on iteration 270 84.71811\n","Current Loss on iteration 271 84.71788\n","Current Loss on iteration 272 84.71766\n","Current Loss on iteration 273 84.71744\n","Current Loss on iteration 274 84.71721\n","Current Loss on iteration 275 84.71699\n","Current Loss on iteration 276 84.716774\n","Current Loss on iteration 277 84.71654\n","Current Loss on iteration 278 84.716324\n","Current Loss on iteration 279 84.7161\n","Current Loss on iteration 280 84.71588\n","Current Loss on iteration 281 84.71567\n","Current Loss on iteration 282 84.71545\n","Current Loss on iteration 283 84.715225\n","Current Loss on iteration 284 84.71501\n","Current Loss on iteration 285 84.71479\n","Current Loss on iteration 286 84.71457\n","Current Loss on iteration 287 84.714355\n","Current Loss on iteration 288 84.714134\n","Current Loss on iteration 289 84.71392\n","Current Loss on iteration 290 84.713715\n","Current Loss on iteration 291 84.71349\n","Current Loss on iteration 292 84.71328\n","Current Loss on iteration 293 84.713066\n","Current Loss on iteration 294 84.71285\n","Current Loss on iteration 295 84.71265\n","Current Loss on iteration 296 84.71243\n","Current Loss on iteration 297 84.71222\n","Current Loss on iteration 298 84.712006\n","Current Loss on iteration 299 84.71181\n","Current Loss on iteration 300 84.711586\n","Current Loss on iteration 301 84.71139\n","Current Loss on iteration 302 84.711174\n","Current Loss on iteration 303 84.71096\n","Current Loss on iteration 304 84.71076\n","Current Loss on iteration 305 84.710556\n","Current Loss on iteration 306 84.71034\n","Current Loss on iteration 307 84.71014\n","Current Loss on iteration 308 84.70993\n","Current Loss on iteration 309 84.70973\n","Current Loss on iteration 310 84.709526\n","Current Loss on iteration 311 84.70931\n","Current Loss on iteration 312 84.70912\n","Current Loss on iteration 313 84.708916\n","Current Loss on iteration 314 84.70871\n","Current Loss on iteration 315 84.70851\n","Current Loss on iteration 316 84.708305\n","Current Loss on iteration 317 84.708115\n","Current Loss on iteration 318 84.7079\n","Current Loss on iteration 319 84.7077\n","Current Loss on iteration 320 84.70751\n","Current Loss on iteration 321 84.707306\n","Current Loss on iteration 322 84.707115\n","Current Loss on iteration 323 84.70692\n","Current Loss on iteration 324 84.70671\n","Current Loss on iteration 325 84.70653\n","Current Loss on iteration 326 84.70632\n","Current Loss on iteration 327 84.70613\n","Current Loss on iteration 328 84.70593\n","Current Loss on iteration 329 84.705734\n","Current Loss on iteration 330 84.70554\n","Current Loss on iteration 331 84.705345\n","Current Loss on iteration 332 84.705154\n","Current Loss on iteration 333 84.70496\n","Current Loss on iteration 334 84.70477\n","Current Loss on iteration 335 84.704575\n","Current Loss on iteration 336 84.704384\n","Current Loss on iteration 337 84.7042\n","Current Loss on iteration 338 84.70401\n","Current Loss on iteration 339 84.703804\n","Current Loss on iteration 340 84.70362\n","Current Loss on iteration 341 84.70343\n","Current Loss on iteration 342 84.70325\n","Current Loss on iteration 343 84.70306\n","Current Loss on iteration 344 84.70287\n","Current Loss on iteration 345 84.70268\n","Current Loss on iteration 346 84.70249\n","Current Loss on iteration 347 84.70232\n","Current Loss on iteration 348 84.70212\n","Current Loss on iteration 349 84.70194\n","Current Loss on iteration 350 84.70175\n","Current Loss on iteration 351 84.70158\n","Current Loss on iteration 352 84.701385\n","Current Loss on iteration 353 84.7012\n","Current Loss on iteration 354 84.70103\n","Current Loss on iteration 355 84.700836\n","Current Loss on iteration 356 84.70065\n","Current Loss on iteration 357 84.70047\n","Current Loss on iteration 358 84.700294\n","Current Loss on iteration 359 84.7001\n","Current Loss on iteration 360 84.699936\n","Current Loss on iteration 361 84.699745\n","Current Loss on iteration 362 84.69957\n","Current Loss on iteration 363 84.699394\n","Current Loss on iteration 364 84.69921\n","Current Loss on iteration 365 84.699036\n","Current Loss on iteration 366 84.69885\n","Current Loss on iteration 367 84.698685\n","Current Loss on iteration 368 84.698494\n","Current Loss on iteration 369 84.698326\n","Current Loss on iteration 370 84.69815\n","Current Loss on iteration 371 84.697975\n","Current Loss on iteration 372 84.69779\n","Current Loss on iteration 373 84.697624\n","Current Loss on iteration 374 84.69745\n","Current Loss on iteration 375 84.69727\n","Current Loss on iteration 376 84.697105\n","Current Loss on iteration 377 84.69693\n","Current Loss on iteration 378 84.69676\n","Current Loss on iteration 379 84.69659\n","Current Loss on iteration 380 84.69642\n","Current Loss on iteration 381 84.69624\n","Current Loss on iteration 382 84.696075\n","Current Loss on iteration 383 84.6959\n","Current Loss on iteration 384 84.69573\n","Current Loss on iteration 385 84.69556\n","Current Loss on iteration 386 84.69539\n","Current Loss on iteration 387 84.69522\n","Current Loss on iteration 388 84.69506\n","Current Loss on iteration 389 84.694885\n","Current Loss on iteration 390 84.694725\n","Current Loss on iteration 391 84.69456\n","Current Loss on iteration 392 84.69439\n","Current Loss on iteration 393 84.694214\n","Current Loss on iteration 394 84.69406\n","Current Loss on iteration 395 84.69389\n","Current Loss on iteration 396 84.69373\n","Current Loss on iteration 397 84.69356\n","Current Loss on iteration 398 84.6934\n","Current Loss on iteration 399 84.69323\n","Current Loss on iteration 400 84.69307\n","Current Loss on iteration 401 84.6929\n","Current Loss on iteration 402 84.69275\n","Current Loss on iteration 403 84.69258\n","Current Loss on iteration 404 84.69242\n","Current Loss on iteration 405 84.69226\n","Current Loss on iteration 406 84.6921\n","Current Loss on iteration 407 84.69193\n","Current Loss on iteration 408 84.69177\n","Current Loss on iteration 409 84.69162\n","Current Loss on iteration 410 84.69145\n","Current Loss on iteration 411 84.6913\n","Current Loss on iteration 412 84.69114\n","Current Loss on iteration 413 84.69098\n","Current Loss on iteration 414 84.69083\n","Current Loss on iteration 415 84.69067\n","Current Loss on iteration 416 84.690506\n","Current Loss on iteration 417 84.690346\n","Current Loss on iteration 418 84.6902\n","Current Loss on iteration 419 84.69004\n","Current Loss on iteration 420 84.68989\n","Current Loss on iteration 421 84.68973\n","Current Loss on iteration 422 84.689575\n","Current Loss on iteration 423 84.689415\n","Current Loss on iteration 424 84.68926\n","Current Loss on iteration 425 84.68912\n","Current Loss on iteration 426 84.688965\n","Current Loss on iteration 427 84.688805\n","Current Loss on iteration 428 84.68865\n","Current Loss on iteration 429 84.68851\n","Current Loss on iteration 430 84.688354\n","Current Loss on iteration 431 84.6882\n","Current Loss on iteration 432 84.68805\n","Current Loss on iteration 433 84.687904\n","Current Loss on iteration 434 84.687744\n","Current Loss on iteration 435 84.6876\n","Current Loss on iteration 436 84.68744\n","Current Loss on iteration 437 84.687294\n","Current Loss on iteration 438 84.68716\n","Current Loss on iteration 439 84.687\n","Current Loss on iteration 440 84.68686\n","Current Loss on iteration 441 84.6867\n","Current Loss on iteration 442 84.68656\n","Current Loss on iteration 443 84.68641\n","Current Loss on iteration 444 84.686264\n","Current Loss on iteration 445 84.68612\n","Current Loss on iteration 446 84.68597\n","Current Loss on iteration 447 84.68583\n","Current Loss on iteration 448 84.685684\n","Current Loss on iteration 449 84.68554\n","Current Loss on iteration 450 84.68539\n","Current Loss on iteration 451 84.68525\n","Current Loss on iteration 452 84.685104\n","Current Loss on iteration 453 84.68496\n","Current Loss on iteration 454 84.68482\n","Current Loss on iteration 455 84.68467\n","Current Loss on iteration 456 84.68454\n","Current Loss on iteration 457 84.68439\n","Current Loss on iteration 458 84.68425\n","Current Loss on iteration 459 84.684105\n","Current Loss on iteration 460 84.68397\n","Current Loss on iteration 461 84.68382\n","Current Loss on iteration 462 84.683685\n","Current Loss on iteration 463 84.68355\n","Current Loss on iteration 464 84.6834\n","Current Loss on iteration 465 84.683266\n","Current Loss on iteration 466 84.68313\n","Current Loss on iteration 467 84.68299\n","Current Loss on iteration 468 84.68285\n","Current Loss on iteration 469 84.68272\n","Current Loss on iteration 470 84.68258\n","Current Loss on iteration 471 84.682434\n","Current Loss on iteration 472 84.682304\n","Current Loss on iteration 473 84.68217\n","Current Loss on iteration 474 84.68203\n","Current Loss on iteration 475 84.681885\n","Current Loss on iteration 476 84.681755\n","Current Loss on iteration 477 84.681625\n","Current Loss on iteration 478 84.68148\n","Current Loss on iteration 479 84.68136\n","Current Loss on iteration 480 84.68121\n","Current Loss on iteration 481 84.68109\n","Current Loss on iteration 482 84.680954\n","Current Loss on iteration 483 84.68082\n","Current Loss on iteration 484 84.68069\n","Current Loss on iteration 485 84.68055\n","Current Loss on iteration 486 84.68042\n","Current Loss on iteration 487 84.6803\n","Current Loss on iteration 488 84.68015\n","Current Loss on iteration 489 84.68003\n","Current Loss on iteration 490 84.679886\n","Current Loss on iteration 491 84.67976\n","Current Loss on iteration 492 84.67964\n","Current Loss on iteration 493 84.6795\n","Current Loss on iteration 494 84.679375\n","Current Loss on iteration 495 84.679245\n","Current Loss on iteration 496 84.67912\n","Current Loss on iteration 497 84.67899\n","Current Loss on iteration 498 84.678856\n","Current Loss on iteration 499 84.678734\n","Current Loss on iteration 500 84.6786\n","Current Loss on iteration 501 84.678474\n","Current Loss on iteration 502 84.678345\n","Current Loss on iteration 503 84.678215\n","Current Loss on iteration 504 84.67809\n","Current Loss on iteration 505 84.67797\n","Current Loss on iteration 506 84.67784\n","Current Loss on iteration 507 84.67772\n","Current Loss on iteration 508 84.67759\n","Current Loss on iteration 509 84.67747\n","Current Loss on iteration 510 84.677345\n","Current Loss on iteration 511 84.677216\n","Current Loss on iteration 512 84.67709\n","Current Loss on iteration 513 84.67696\n","Current Loss on iteration 514 84.67684\n","Current Loss on iteration 515 84.67673\n","Current Loss on iteration 516 84.6766\n","Current Loss on iteration 517 84.676476\n","Current Loss on iteration 518 84.67635\n","Current Loss on iteration 519 84.67623\n","Current Loss on iteration 520 84.67611\n","Current Loss on iteration 521 84.67598\n","Current Loss on iteration 522 84.67587\n","Current Loss on iteration 523 84.67575\n","Current Loss on iteration 524 84.67562\n","Current Loss on iteration 525 84.67551\n","Current Loss on iteration 526 84.675385\n","Current Loss on iteration 527 84.67526\n","Current Loss on iteration 528 84.67514\n","Current Loss on iteration 529 84.67503\n","Current Loss on iteration 530 84.674904\n","Current Loss on iteration 531 84.67479\n","Current Loss on iteration 532 84.67467\n","Current Loss on iteration 533 84.674545\n","Current Loss on iteration 534 84.67444\n","Current Loss on iteration 535 84.67431\n","Current Loss on iteration 536 84.674194\n","Current Loss on iteration 537 84.67409\n","Current Loss on iteration 538 84.673965\n","Current Loss on iteration 539 84.67386\n","Current Loss on iteration 540 84.67374\n","Current Loss on iteration 541 84.67362\n","Current Loss on iteration 542 84.6735\n","Current Loss on iteration 543 84.67339\n","Current Loss on iteration 544 84.67327\n","Current Loss on iteration 545 84.673164\n","Current Loss on iteration 546 84.67304\n","Current Loss on iteration 547 84.67293\n","Current Loss on iteration 548 84.67281\n","Current Loss on iteration 549 84.6727\n","Current Loss on iteration 550 84.67259\n","Current Loss on iteration 551 84.67248\n","Current Loss on iteration 552 84.67236\n","Current Loss on iteration 553 84.67225\n","Current Loss on iteration 554 84.67214\n","Current Loss on iteration 555 84.67203\n","Current Loss on iteration 556 84.67192\n","Current Loss on iteration 557 84.671814\n","Current Loss on iteration 558 84.671684\n","Current Loss on iteration 559 84.67158\n","Current Loss on iteration 560 84.67147\n","Current Loss on iteration 561 84.671364\n","Current Loss on iteration 562 84.67125\n","Current Loss on iteration 563 84.67114\n","Current Loss on iteration 564 84.67103\n","Current Loss on iteration 565 84.67092\n","Current Loss on iteration 566 84.670815\n","Current Loss on iteration 567 84.67071\n","Current Loss on iteration 568 84.67059\n","Current Loss on iteration 569 84.670494\n","Current Loss on iteration 570 84.67038\n","Current Loss on iteration 571 84.67027\n","Current Loss on iteration 572 84.67017\n","Current Loss on iteration 573 84.67006\n","Current Loss on iteration 574 84.66995\n","Current Loss on iteration 575 84.669846\n","Current Loss on iteration 576 84.66973\n","Current Loss on iteration 577 84.66963\n","Current Loss on iteration 578 84.66953\n","Current Loss on iteration 579 84.66942\n","Current Loss on iteration 580 84.66931\n","Current Loss on iteration 581 84.66921\n","Current Loss on iteration 582 84.669106\n","Current Loss on iteration 583 84.669\n","Current Loss on iteration 584 84.66889\n","Current Loss on iteration 585 84.6688\n","Current Loss on iteration 586 84.668686\n","Current Loss on iteration 587 84.66858\n","Current Loss on iteration 588 84.66849\n","Current Loss on iteration 589 84.66837\n","Current Loss on iteration 590 84.66828\n","Current Loss on iteration 591 84.668175\n","Current Loss on iteration 592 84.668076\n","Current Loss on iteration 593 84.66797\n","Current Loss on iteration 594 84.66788\n","Current Loss on iteration 595 84.66776\n","Current Loss on iteration 596 84.66766\n","Current Loss on iteration 597 84.667564\n","Current Loss on iteration 598 84.667465\n","Current Loss on iteration 599 84.66736\n","Current Loss on iteration 600 84.66726\n","Current Loss on iteration 601 84.66717\n","Current Loss on iteration 602 84.66706\n","Current Loss on iteration 603 84.66697\n","Current Loss on iteration 604 84.66686\n","Current Loss on iteration 605 84.66676\n","Current Loss on iteration 606 84.666664\n","Current Loss on iteration 607 84.666565\n","Current Loss on iteration 608 84.666466\n","Current Loss on iteration 609 84.66637\n","Current Loss on iteration 610 84.66627\n","Current Loss on iteration 611 84.66617\n","Current Loss on iteration 612 84.66607\n","Current Loss on iteration 613 84.66598\n","Current Loss on iteration 614 84.665886\n","Current Loss on iteration 615 84.66578\n","Current Loss on iteration 616 84.66569\n","Current Loss on iteration 617 84.665596\n","Current Loss on iteration 618 84.6655\n","Current Loss on iteration 619 84.66539\n","Current Loss on iteration 620 84.6653\n","Current Loss on iteration 621 84.66521\n","Current Loss on iteration 622 84.66511\n","Current Loss on iteration 623 84.665016\n","Current Loss on iteration 624 84.664925\n","Current Loss on iteration 625 84.664825\n","Current Loss on iteration 626 84.664734\n","Current Loss on iteration 627 84.66464\n","Current Loss on iteration 628 84.66455\n","Current Loss on iteration 629 84.664444\n","Current Loss on iteration 630 84.66435\n","Current Loss on iteration 631 84.66427\n","Current Loss on iteration 632 84.66417\n","Current Loss on iteration 633 84.66408\n","Current Loss on iteration 634 84.66399\n","Current Loss on iteration 635 84.663895\n","Current Loss on iteration 636 84.663795\n","Current Loss on iteration 637 84.663704\n","Current Loss on iteration 638 84.66361\n","Current Loss on iteration 639 84.66353\n","Current Loss on iteration 640 84.66344\n","Current Loss on iteration 641 84.663345\n","Current Loss on iteration 642 84.66325\n","Current Loss on iteration 643 84.66316\n","Current Loss on iteration 644 84.66307\n","Current Loss on iteration 645 84.66299\n","Current Loss on iteration 646 84.66289\n","Current Loss on iteration 647 84.662796\n","Current Loss on iteration 648 84.66271\n","Current Loss on iteration 649 84.66263\n","Current Loss on iteration 650 84.66253\n","Current Loss on iteration 651 84.66244\n","Current Loss on iteration 652 84.66235\n","Current Loss on iteration 653 84.66227\n","Current Loss on iteration 654 84.66217\n","Current Loss on iteration 655 84.662094\n","Current Loss on iteration 656 84.662\n","Current Loss on iteration 657 84.66191\n","Current Loss on iteration 658 84.66183\n","Current Loss on iteration 659 84.661736\n","Current Loss on iteration 660 84.66165\n","Current Loss on iteration 661 84.66156\n","Current Loss on iteration 662 84.66148\n","Current Loss on iteration 663 84.66139\n","Current Loss on iteration 664 84.661316\n","Current Loss on iteration 665 84.66122\n","Current Loss on iteration 666 84.66113\n","Current Loss on iteration 667 84.66105\n","Current Loss on iteration 668 84.66096\n","Current Loss on iteration 669 84.66087\n","Current Loss on iteration 670 84.66079\n","Current Loss on iteration 671 84.660706\n","Current Loss on iteration 672 84.66062\n","Current Loss on iteration 673 84.66054\n","Current Loss on iteration 674 84.66045\n","Current Loss on iteration 675 84.66036\n","Current Loss on iteration 676 84.660286\n","Current Loss on iteration 677 84.6602\n","Current Loss on iteration 678 84.660126\n","Current Loss on iteration 679 84.660034\n","Current Loss on iteration 680 84.65995\n","Current Loss on iteration 681 84.659874\n","Current Loss on iteration 682 84.65978\n","Current Loss on iteration 683 84.659706\n","Current Loss on iteration 684 84.65962\n","Current Loss on iteration 685 84.65954\n","Current Loss on iteration 686 84.659454\n","Current Loss on iteration 687 84.65938\n","Current Loss on iteration 688 84.659294\n","Current Loss on iteration 689 84.65921\n","Current Loss on iteration 690 84.65913\n","Current Loss on iteration 691 84.65905\n","Current Loss on iteration 692 84.658966\n","Current Loss on iteration 693 84.65889\n","Current Loss on iteration 694 84.65881\n","Current Loss on iteration 695 84.65874\n","Current Loss on iteration 696 84.65865\n","Current Loss on iteration 697 84.65856\n","Current Loss on iteration 698 84.658485\n","Current Loss on iteration 699 84.65841\n","Current Loss on iteration 700 84.65833\n","Current Loss on iteration 701 84.65825\n","Current Loss on iteration 702 84.658165\n","Current Loss on iteration 703 84.6581\n","Current Loss on iteration 704 84.65802\n","Current Loss on iteration 705 84.657936\n","Current Loss on iteration 706 84.65786\n","Current Loss on iteration 707 84.65778\n","Current Loss on iteration 708 84.65771\n","Current Loss on iteration 709 84.65762\n","Current Loss on iteration 710 84.65755\n","Current Loss on iteration 711 84.65747\n","Current Loss on iteration 712 84.657394\n","Current Loss on iteration 713 84.65731\n","Current Loss on iteration 714 84.657234\n","Current Loss on iteration 715 84.65716\n","Current Loss on iteration 716 84.65709\n","Current Loss on iteration 717 84.65701\n","Current Loss on iteration 718 84.65693\n","Current Loss on iteration 719 84.65685\n","Current Loss on iteration 720 84.656784\n","Current Loss on iteration 721 84.656715\n","Current Loss on iteration 722 84.656624\n","Current Loss on iteration 723 84.656555\n","Current Loss on iteration 724 84.65649\n","Current Loss on iteration 725 84.65641\n","Current Loss on iteration 726 84.65633\n","Current Loss on iteration 727 84.65625\n","Current Loss on iteration 728 84.65618\n","Current Loss on iteration 729 84.656105\n","Current Loss on iteration 730 84.65604\n","Current Loss on iteration 731 84.65595\n","Current Loss on iteration 732 84.65589\n","Current Loss on iteration 733 84.655815\n","Current Loss on iteration 734 84.65574\n","Current Loss on iteration 735 84.65566\n","Current Loss on iteration 736 84.655594\n","Current Loss on iteration 737 84.65552\n","Current Loss on iteration 738 84.65545\n","Current Loss on iteration 739 84.65538\n","Current Loss on iteration 740 84.655304\n","Current Loss on iteration 741 84.655235\n","Current Loss on iteration 742 84.65516\n","Current Loss on iteration 743 84.65508\n","Current Loss on iteration 744 84.65501\n","Current Loss on iteration 745 84.65494\n","Current Loss on iteration 746 84.65488\n","Current Loss on iteration 747 84.6548\n","Current Loss on iteration 748 84.65473\n","Current Loss on iteration 749 84.654655\n","Current Loss on iteration 750 84.65459\n","Current Loss on iteration 751 84.65452\n","Current Loss on iteration 752 84.65445\n","Current Loss on iteration 753 84.65437\n","Current Loss on iteration 754 84.654305\n","Current Loss on iteration 755 84.65424\n","Current Loss on iteration 756 84.654175\n","Current Loss on iteration 757 84.654106\n","Current Loss on iteration 758 84.65403\n","Current Loss on iteration 759 84.65395\n","Current Loss on iteration 760 84.65389\n","Current Loss on iteration 761 84.653824\n","Current Loss on iteration 762 84.653755\n","Current Loss on iteration 763 84.65369\n","Current Loss on iteration 764 84.65361\n","Current Loss on iteration 765 84.65355\n","Current Loss on iteration 766 84.65348\n","Current Loss on iteration 767 84.65341\n","Current Loss on iteration 768 84.65334\n","Current Loss on iteration 769 84.653275\n","Current Loss on iteration 770 84.653206\n","Current Loss on iteration 771 84.653145\n","Current Loss on iteration 772 84.65307\n","Current Loss on iteration 773 84.653\n","Current Loss on iteration 774 84.65294\n","Current Loss on iteration 775 84.65288\n","Current Loss on iteration 776 84.65282\n","Current Loss on iteration 777 84.65274\n","Current Loss on iteration 778 84.65267\n","Current Loss on iteration 779 84.65261\n","Current Loss on iteration 780 84.65254\n","Current Loss on iteration 781 84.65248\n","Current Loss on iteration 782 84.652405\n","Current Loss on iteration 783 84.65234\n","Current Loss on iteration 784 84.65228\n","Current Loss on iteration 785 84.65221\n","Current Loss on iteration 786 84.65215\n","Current Loss on iteration 787 84.65208\n","Current Loss on iteration 788 84.65202\n","Current Loss on iteration 789 84.651955\n","Current Loss on iteration 790 84.65189\n","Current Loss on iteration 791 84.65183\n","Current Loss on iteration 792 84.651764\n","Current Loss on iteration 793 84.65169\n","Current Loss on iteration 794 84.651634\n","Current Loss on iteration 795 84.65157\n","Current Loss on iteration 796 84.651505\n","Current Loss on iteration 797 84.651436\n","Current Loss on iteration 798 84.651375\n","Current Loss on iteration 799 84.65131\n","Current Loss on iteration 800 84.65125\n","Current Loss on iteration 801 84.65119\n","Current Loss on iteration 802 84.65113\n","Current Loss on iteration 803 84.65106\n","Current Loss on iteration 804 84.651\n","Current Loss on iteration 805 84.65094\n","Current Loss on iteration 806 84.65088\n","Current Loss on iteration 807 84.65082\n","Current Loss on iteration 808 84.65075\n","Current Loss on iteration 809 84.65069\n","Current Loss on iteration 810 84.65063\n","Current Loss on iteration 811 84.650566\n","Current Loss on iteration 812 84.65051\n","Current Loss on iteration 813 84.65045\n","Current Loss on iteration 814 84.65038\n","Current Loss on iteration 815 84.65033\n","Current Loss on iteration 816 84.65027\n","Current Loss on iteration 817 84.65021\n","Current Loss on iteration 818 84.65015\n","Current Loss on iteration 819 84.65008\n","Current Loss on iteration 820 84.65002\n","Current Loss on iteration 821 84.649956\n","Current Loss on iteration 822 84.6499\n","Current Loss on iteration 823 84.64984\n","Current Loss on iteration 824 84.64978\n","Current Loss on iteration 825 84.64972\n","Current Loss on iteration 826 84.649666\n","Current Loss on iteration 827 84.649605\n","Current Loss on iteration 828 84.64954\n","Current Loss on iteration 829 84.64949\n","Current Loss on iteration 830 84.64942\n","Current Loss on iteration 831 84.64937\n","Current Loss on iteration 832 84.649315\n","Current Loss on iteration 833 84.649254\n","Current Loss on iteration 834 84.64919\n","Current Loss on iteration 835 84.64913\n","Current Loss on iteration 836 84.64908\n","Current Loss on iteration 837 84.64902\n","Current Loss on iteration 838 84.648964\n","Current Loss on iteration 839 84.6489\n","Current Loss on iteration 840 84.64885\n","Current Loss on iteration 841 84.64878\n","Current Loss on iteration 842 84.64873\n","Current Loss on iteration 843 84.648674\n","Current Loss on iteration 844 84.64861\n","Current Loss on iteration 845 84.64856\n","Current Loss on iteration 846 84.648506\n","Current Loss on iteration 847 84.64844\n","Current Loss on iteration 848 84.648384\n","Current Loss on iteration 849 84.64833\n","Current Loss on iteration 850 84.64828\n","Current Loss on iteration 851 84.648224\n","Current Loss on iteration 852 84.64817\n","Current Loss on iteration 853 84.6481\n","Current Loss on iteration 854 84.64805\n","Current Loss on iteration 855 84.647995\n","Current Loss on iteration 856 84.64794\n","Current Loss on iteration 857 84.64788\n","Current Loss on iteration 858 84.64782\n","Current Loss on iteration 859 84.647766\n","Current Loss on iteration 860 84.64772\n","Current Loss on iteration 861 84.64767\n","Current Loss on iteration 862 84.647606\n","Current Loss on iteration 863 84.64755\n","Current Loss on iteration 864 84.6475\n","Current Loss on iteration 865 84.647446\n","Current Loss on iteration 866 84.64739\n","Current Loss on iteration 867 84.64734\n","Current Loss on iteration 868 84.647285\n","Current Loss on iteration 869 84.64723\n","Current Loss on iteration 870 84.64717\n","Current Loss on iteration 871 84.647125\n","Current Loss on iteration 872 84.647064\n","Current Loss on iteration 873 84.64701\n","Current Loss on iteration 874 84.64696\n","Current Loss on iteration 875 84.64691\n","Current Loss on iteration 876 84.64685\n","Current Loss on iteration 877 84.6468\n","Current Loss on iteration 878 84.64675\n","Current Loss on iteration 879 84.6467\n","Current Loss on iteration 880 84.646645\n","Current Loss on iteration 881 84.6466\n","Current Loss on iteration 882 84.64654\n","Current Loss on iteration 883 84.646484\n","Current Loss on iteration 884 84.64643\n","Current Loss on iteration 885 84.64638\n","Current Loss on iteration 886 84.646324\n","Current Loss on iteration 887 84.64627\n","Current Loss on iteration 888 84.646225\n","Current Loss on iteration 889 84.64617\n","Current Loss on iteration 890 84.64612\n","Current Loss on iteration 891 84.646065\n","Current Loss on iteration 892 84.64602\n","Current Loss on iteration 893 84.64597\n","Current Loss on iteration 894 84.64591\n","Current Loss on iteration 895 84.64586\n","Current Loss on iteration 896 84.64581\n","Current Loss on iteration 897 84.64576\n","Current Loss on iteration 898 84.64571\n","Current Loss on iteration 899 84.64566\n","Current Loss on iteration 900 84.645615\n","Current Loss on iteration 901 84.64556\n","Current Loss on iteration 902 84.64551\n","Current Loss on iteration 903 84.645454\n","Current Loss on iteration 904 84.64541\n","Current Loss on iteration 905 84.64536\n","Current Loss on iteration 906 84.64531\n","Current Loss on iteration 907 84.645256\n","Current Loss on iteration 908 84.6452\n","Current Loss on iteration 909 84.64516\n","Current Loss on iteration 910 84.64511\n","Current Loss on iteration 911 84.64506\n","Current Loss on iteration 912 84.64502\n","Current Loss on iteration 913 84.64496\n","Current Loss on iteration 914 84.64491\n","Current Loss on iteration 915 84.64486\n","Current Loss on iteration 916 84.64481\n","Current Loss on iteration 917 84.64477\n","Current Loss on iteration 918 84.64472\n","Current Loss on iteration 919 84.64468\n","Current Loss on iteration 920 84.64462\n","Current Loss on iteration 921 84.644585\n","Current Loss on iteration 922 84.64452\n","Current Loss on iteration 923 84.64448\n","Current Loss on iteration 924 84.644424\n","Current Loss on iteration 925 84.64438\n","Current Loss on iteration 926 84.64433\n","Current Loss on iteration 927 84.64429\n","Current Loss on iteration 928 84.64425\n","Current Loss on iteration 929 84.64419\n","Current Loss on iteration 930 84.64414\n","Current Loss on iteration 931 84.6441\n","Current Loss on iteration 932 84.64405\n","Current Loss on iteration 933 84.644005\n","Current Loss on iteration 934 84.64396\n","Current Loss on iteration 935 84.643906\n","Current Loss on iteration 936 84.64386\n","Current Loss on iteration 937 84.643814\n","Current Loss on iteration 938 84.64377\n","Current Loss on iteration 939 84.64372\n","Current Loss on iteration 940 84.64368\n","Current Loss on iteration 941 84.64363\n","Current Loss on iteration 942 84.64358\n","Current Loss on iteration 943 84.64353\n","Current Loss on iteration 944 84.64349\n","Current Loss on iteration 945 84.64344\n","Current Loss on iteration 946 84.6434\n","Current Loss on iteration 947 84.64336\n","Current Loss on iteration 948 84.64332\n","Current Loss on iteration 949 84.64327\n","Current Loss on iteration 950 84.64322\n","Current Loss on iteration 951 84.64317\n","Current Loss on iteration 952 84.64313\n","Current Loss on iteration 953 84.64308\n","Current Loss on iteration 954 84.643036\n","Current Loss on iteration 955 84.643\n","Current Loss on iteration 956 84.64295\n","Current Loss on iteration 957 84.6429\n","Current Loss on iteration 958 84.64286\n","Current Loss on iteration 959 84.642815\n","Current Loss on iteration 960 84.64277\n","Current Loss on iteration 961 84.64272\n","Current Loss on iteration 962 84.642685\n","Current Loss on iteration 963 84.64265\n","Current Loss on iteration 964 84.64259\n","Current Loss on iteration 965 84.642555\n","Current Loss on iteration 966 84.64251\n","Current Loss on iteration 967 84.64246\n","Current Loss on iteration 968 84.642426\n","Current Loss on iteration 969 84.64238\n","Current Loss on iteration 970 84.642334\n","Current Loss on iteration 971 84.64229\n","Current Loss on iteration 972 84.64224\n","Current Loss on iteration 973 84.642204\n","Current Loss on iteration 974 84.64216\n","Current Loss on iteration 975 84.64211\n","Current Loss on iteration 976 84.642075\n","Current Loss on iteration 977 84.64203\n","Current Loss on iteration 978 84.64199\n","Current Loss on iteration 979 84.64194\n","Current Loss on iteration 980 84.64191\n","Current Loss on iteration 981 84.64186\n","Current Loss on iteration 982 84.641815\n","Current Loss on iteration 983 84.641785\n","Current Loss on iteration 984 84.64174\n","Current Loss on iteration 985 84.64169\n","Current Loss on iteration 986 84.641655\n","Current Loss on iteration 987 84.6416\n","Current Loss on iteration 988 84.64156\n","Current Loss on iteration 989 84.641525\n","Current Loss on iteration 990 84.64149\n","Current Loss on iteration 991 84.64144\n","Current Loss on iteration 992 84.641396\n","Current Loss on iteration 993 84.641365\n","Current Loss on iteration 994 84.64132\n","Current Loss on iteration 995 84.64128\n","Current Loss on iteration 996 84.641235\n","Current Loss on iteration 997 84.64119\n","Current Loss on iteration 998 84.64115\n","Current Loss on iteration 999 84.64111\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DDcxSozRxyer","colab_type":"code","outputId":"6abae3d6-e754-4962-97c2-f3e6df8e2d51","executionInfo":{"status":"ok","timestamp":1561376535139,"user_tz":-330,"elapsed":737,"user":{"displayName":"Nikhil Madhusudhan","photoUrl":"https://lh4.googleusercontent.com/-YnXjatesaTE/AAAAAAAAAAI/AAAAAAAAACU/kzbw4Qh1c_g/s64/photo.jpg","userId":"15028125124945084753"}},"colab":{"base_uri":"https://localhost:8080/","height":286}},"source":["#Check Weights and Bias\n","print('Weights:\\n', w.numpy())\n","print('Bias:\\n',b.numpy())"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Weights:\n"," [[1.0037384e-01]\n"," [2.7188399e-01]\n"," [2.3631376e-01]\n"," [1.3886957e-03]\n"," [1.2006560e-02]\n"," [1.3788167e-01]\n"," [1.4666847e+00]\n"," [8.2598507e-02]\n"," [2.1812938e-01]\n"," [8.6239433e+00]\n"," [4.0184519e-01]\n"," [6.6856766e+00]\n"," [2.8008005e-01]]\n","Bias:\n"," [11.950446]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zr7L77vmLjGp","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MGJwv9pqTjVJ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}